# Accessibility Testing Workflow
# This workflow runs accessibility tests on deployed sites
name: 'A11y scan'

# Controls when the action will run
on:
  # Automatic trigger after successful deployment
  workflow_call:
    secrets:
      GH_TOKEN:
        required: true
    inputs:
      url:
        description: 'Site URL to test (e.g., https://th3s4mur41.me)'
        required: true
        default: 'https://th3s4mur41.me'
        type: string

  # Manual trigger with custom URL
  workflow_dispatch:
    inputs:
      url:
        description: 'Site URL to test (e.g., https://th3s4mur41.me)'
        required: true
        default: 'https://th3s4mur41.me'
        type: string

jobs:
  accessibility-test:
    name: 'â™¿ Accessibility Testing'
    runs-on: ubuntu-latest

    # Only run if manually triggered OR if the workflow succeeded and wasn't triggered by dependabot
    if: ${{ github.event_name == 'workflow_dispatch' || (github.event.workflow_run.conclusion == 'success' && github.actor != 'dependabot[bot]') }}

    permissions:
      contents: read
      issues: write
      pull-requests: write

    steps:
      - name: 'ðŸ“‹ Extract URLs from deployed sitemap'
        id: extract-urls
        run: |
          site_url="${{ inputs.url }}"
          sitemap_index_url="${site_url}/sitemap-index.xml"

          echo "Fetching sitemap index from: $sitemap_index_url"

          # Download the sitemap index with headers to bypass Cloudflare
          curl -s \
            -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36" \
            -H "Accept: application/xml,text/xml,*/*" \
            -H "Accept-Language: en-US,en;q=0.9" \
            -H "Accept-Encoding: gzip, deflate, br" \
            -H "Cache-Control: no-cache" \
            -H "Pragma: no-cache" \
            --compressed \
            "$sitemap_index_url" -o sitemap-index.xml

          # Check if sitemap index was downloaded successfully
          if [ ! -f sitemap-index.xml ] || [ ! -s sitemap-index.xml ]; then
            echo "Error: Could not download sitemap index from $sitemap_index_url"
            exit 1
          fi

          # Debug: Show what we downloaded
          echo "Sitemap index content (first 500 chars):"
          head -c 500 sitemap-index.xml
          echo ""

          # Extract sitemap URLs from the index
          sitemap_urls=$(grep -o '<loc>[^<]*</loc>' sitemap-index.xml | sed 's/<loc>//g; s/<\/loc>//g' | tr -d '\r')

          if [ -z "$sitemap_urls" ]; then
            echo "Error: No sitemap URLs found in sitemap index"
            echo "Full sitemap index content:"
            cat sitemap-index.xml
            exit 1
          fi

          echo "Found sitemaps:"
          echo "$sitemap_urls"

          # Fetch all URLs from each sitemap
          all_urls=""
          for sitemap_url in $sitemap_urls; do
            echo "Fetching sitemap: $sitemap_url"
            sitemap_content=$(curl -s \
              -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36" \
              -H "Accept: application/xml,text/xml,*/*" \
              -H "Accept-Language: en-US,en;q=0.9" \
              -H "Accept-Encoding: gzip, deflate, br" \
              --compressed \
              "$sitemap_url")
            
            if [ -z "$sitemap_content" ]; then
              echo "Warning: Could not fetch $sitemap_url"
              continue
            fi
            
            # Extract URLs from this sitemap
            urls=$(echo "$sitemap_content" | grep -o '<loc>[^<]*</loc>' | sed 's/<loc>//g; s/<\/loc>//g')
            all_urls="${all_urls}${urls}"$'\n'
          done

          # Remove empty lines and trailing newline
          all_urls=$(echo "$all_urls" | sed '/^$/d')

          if [ -z "$all_urls" ]; then
            echo "Error: No URLs found in any sitemap"
            exit 1
          fi

          # Count URLs
          url_count=$(echo "$all_urls" | wc -l)
          echo "url_count=$url_count" >> $GITHUB_OUTPUT

          # Store URLs for the accessibility scanner (newline-delimited format)
          echo "urls_list<<EOF" >> $GITHUB_OUTPUT
          echo "$all_urls" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          echo "Found $url_count URLs to test for accessibility:"
          echo "$all_urls"

      - name: 'â™¿ Run Accessibility Scanner'
        uses: github/accessibility-scanner@v2
        with:
          # Newline-delimited list of URLs to scan
          urls: ${{ steps.extract-urls.outputs.urls_list }}

          # Repository where issues will be filed
          repository: ${{ github.repository }}

          # Token with required permissions (requires PAT, not GITHUB_TOKEN)
          # You'll need to create a fine-grained PAT and add it as a secret named GH_TOKEN
          token: ${{ secrets.GH_TOKEN }}

          # Cache key for results
          cache_key: 'accessibility-scan-${{ github.event.workflow_run.head_branch }}-${{ github.event.workflow_run.head_sha }}'

          # Skip Copilot assignment for now (you can enable this later)
          skip_copilot_assignment: true

      - name: 'âœ… Accessibility scan completed'
        run: |
          echo "â™¿ Accessibility scan completed for ${{ steps.extract-urls.outputs.url_count }} URLs"
          echo "Any accessibility issues found will be automatically filed as GitHub issues"
          echo "Check the Issues tab for detailed reports and Copilot-suggested fixes"
